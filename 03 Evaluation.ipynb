{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from visualisationMetrics import *\n",
    "from dataLoader import *\n",
    "from utils.utils import *\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSETS = 20\n",
    "LOGDIR = 'reweighted_with_var'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape is (4344, 1, 1, 3), X_test's shape is (485, 1, 1, 3)\n",
      "y_train's label shape is (4344, 1, 1, 43), y_test's label shape is (485, 1, 1, 43)\n"
     ]
    }
   ],
   "source": [
    "real_data = load_dataset(data_mode='Train')\n",
    "real_dataloader = data.DataLoader(real_data, batch_size=1, num_workers=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485, 1, 43)\n",
      "(485, 1, 3)\n",
      "(485, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "real_paths = []\n",
    "real_conds = []\n",
    "\n",
    "for i, (cond, sim) in enumerate(real_dataloader):\n",
    "    sim = sim.cpu().detach().numpy()\n",
    "    sim = sim.reshape(sim.shape[1], sim.shape[3])\n",
    "    real_paths.append(sim)\n",
    "    cond = cond.cpu().detach().numpy()\n",
    "    cond = cond.reshape(cond.shape[1], cond.shape[3])\n",
    "    real_conds.append(cond)\n",
    "\n",
    "real_paths = np.array(real_paths)\n",
    "real_conds = np.array(real_conds)\n",
    "print(real_paths.shape)\n",
    "print(real_conds.shape)\n",
    "\n",
    "real_vals = np.transpose(real_paths, (0,2,1))\n",
    "print(real_vals.shape)\n",
    "to_pkl(f'results/real_vals.pkl', real_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoadSynthetic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syn_vals(model_path=f'./logs/{LOGDIR}', n=10, **kwargs):\n",
    "    syn_data = Synthetic_Dataset(model_path=model_path, n=n, dataset=real_data, **kwargs)\n",
    "    dataloader = data.DataLoader(syn_data, batch_size=1, num_workers=1, shuffle=True, **kwargs)\n",
    "\n",
    "    paths = []\n",
    "    conds = []\n",
    "\n",
    "    for i, (cond, sim) in enumerate(dataloader):\n",
    "        sim = sim.cpu().detach().numpy()\n",
    "        sim = sim.reshape(sim.shape[1], sim.shape[3])\n",
    "        paths.append(sim)\n",
    "        cond = cond.cpu().detach().numpy()\n",
    "        cond = cond.reshape(cond.shape[1], cond.shape[3])\n",
    "        conds.append(cond)\n",
    "        \n",
    "    paths = np.array(paths)\n",
    "    conds = np.array(conds)\n",
    "    vals = np.transpose(paths, (0,2,1))\n",
    "    np.random.shuffle(vals)\n",
    "    return vals\n",
    "\n",
    "def get_syn_val_sets(nsets, **kwargs):\n",
    "    val_sets = []\n",
    "    for i in tqdm(range(nsets)):\n",
    "        val_sets.append(get_syn_vals(**kwargs))\n",
    "    return val_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:55<00:00, 20.79s/it]\n"
     ]
    }
   ],
   "source": [
    "syn_val_sets = get_syn_val_sets(nsets=NSETS)\n",
    "to_pkl(f'logs/{LOGDIR}/results/syn_val_sets.pkl', syn_val_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_vals(n=10, mode='gbm', **kwargs):\n",
    "    if mode=='gbm':\n",
    "        simulator = GBM_Simulator(dataset=real_data, nsamples=n)\n",
    "    elif mode=='cev':\n",
    "        simulator = CEV_Simulator(dataset=real_data, nsamples=n)\n",
    "    elif mode=='heston':\n",
    "        simulator = Heston_Simulator(dataset=real_data, nsamples=n)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    paths = simulator.run()\n",
    "    paths = np.reshape(paths, (-1,1,paths.shape[-1]))\n",
    "\n",
    "    vals = np.transpose(paths, (0, 2, 1))\n",
    "    np.random.shuffle(vals)\n",
    "    return vals\n",
    "\n",
    "def get_benchmark_val_sets(nsets, mode='gbm', **kwargs):\n",
    "    val_sets = []\n",
    "    for i in tqdm(range(nsets)):\n",
    "        val_sets.append(get_benchmark_vals(mode=mode, **kwargs))\n",
    "    return val_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['gbm', 'cev', 'heston']:\n",
    "    benchmark_val_sets = get_benchmark_val_sets(mode=mode, nsets=NSETS)\n",
    "    to_pkl(f'results/{mode}_val_sets.pkl', benchmark_val_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vals = from_pkl(f'results/real_vals.pkl')\n",
    "syn_val_sets = from_pkl(f'logs/{LOGDIR}/results/syn_val_sets.pkl')\n",
    "gbm_val_sets = from_pkl(f'results/gbm_val_sets.pkl')\n",
    "cev_val_sets = from_pkl(f'results/cev_val_sets.pkl')\n",
    "heston_val_sets = from_pkl(f'results/heston_val_sets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores = {\n",
    "    'js_pca': {\n",
    "        'syn': [],\n",
    "        'gbm': [],\n",
    "        'cev': [],\n",
    "        'heston': []\n",
    "    },\n",
    "    'js_tsne': {\n",
    "        'syn': [],\n",
    "        'gbm': [],\n",
    "        'cev': [],\n",
    "        'heston': []\n",
    "    },\n",
    "    'fid': {\n",
    "        'syn': [],\n",
    "        'gbm': [],\n",
    "        'cev': [],\n",
    "        'heston': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_div(real_vals, other_vals_list, mode, n_components=10, **kwargs):\n",
    "    \n",
    "    vals_list = dim_reduction([real_vals]+other_vals_list, n_components=n_components, mode=mode, **kwargs)\n",
    "\n",
    "    scores = []\n",
    "    for i in range(1,len(other_vals_list)+1):\n",
    "        scores.append(js_divergence(vals_list[0], vals_list[i], verbose=False))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [05:43, 17.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for syn_vals, gbm_vals, cev_vals, heston_vals in tqdm(zip(syn_val_sets, gbm_val_sets, cev_val_sets, heston_val_sets)):\n",
    "    with io.capture_output() as o:\n",
    "        for iter in range(3):\n",
    "            # JS-PCA\n",
    "            syn_score, gbm_score, cev_score, heston_score  = js_div(real_vals, [syn_vals, gbm_vals, cev_vals, heston_vals], mode='pca')\n",
    "            eval_scores['js_pca']['syn'].append(syn_score)\n",
    "            eval_scores['js_pca']['gbm'].append(gbm_score)\n",
    "            eval_scores['js_pca']['cev'].append(cev_score)\n",
    "            eval_scores['js_pca']['heston'].append(heston_score)\n",
    "            \n",
    "            # JS-TSNE\n",
    "            syn_score, gbm_score, cev_score, heston_score = js_div(real_vals, [syn_vals, gbm_vals, cev_vals, heston_vals], mode='tsne')\n",
    "            eval_scores['js_tsne']['syn'].append(syn_score)\n",
    "            eval_scores['js_tsne']['gbm'].append(gbm_score)\n",
    "            eval_scores['js_tsne']['cev'].append(cev_score)\n",
    "            eval_scores['js_tsne']['heston'].append(heston_score)\n",
    "        \n",
    "        # FID\n",
    "        syn_score = fid(real_vals, syn_vals)\n",
    "        gbm_score = fid(real_vals, gbm_vals)\n",
    "        cev_score = fid(real_vals, cev_vals)\n",
    "        heston_score = fid(real_vals, heston_vals)\n",
    "        eval_scores['fid']['syn'].append(syn_score)\n",
    "        eval_scores['fid']['gbm'].append(gbm_score)\n",
    "        eval_scores['fid']['cev'].append(cev_score)\n",
    "        eval_scores['fid']['heston'].append(heston_score)\n",
    "\n",
    "to_pkl(f'logs/{LOGDIR}/results/eval_scores.pkl', eval_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run hypothesis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "eval_scores = from_pkl(f'logs/{LOGDIR}/results/eval_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_test(syn_scores, gbm_scores):\n",
    "    syn_scores = np.array(syn_scores)\n",
    "    gbm_scores = np.array(gbm_scores)\n",
    "    print(\"Synthetic:\")\n",
    "    print(f\"\\tmean  = {syn_scores.mean()}\")\n",
    "    print(f\"\\tstdev = {syn_scores.std(ddof=1)}\")\n",
    "    print(\"Benchmark:\")\n",
    "    print(f\"\\tmean  = {gbm_scores.mean()}\")\n",
    "    print(f\"\\tstdev = {gbm_scores.std(ddof=1)}\")\n",
    "\n",
    "    p_value = ttest_ind(syn_scores, gbm_scores, alternative='less').pvalue \n",
    "    print(f\"p-value = {p_value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA JS-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 6.1102822580830445\n",
      "\tstdev = 0.4233422107915738\n",
      "Benchmark:\n",
      "\tmean  = 7.283053824594976\n",
      "\tstdev = 0.5052557238577574\n",
      "p-value = 1.81174700602567e-27\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_pca']['syn'], eval_scores['js_pca']['gbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 6.1102822580830445\n",
      "\tstdev = 0.4233422107915738\n",
      "Benchmark:\n",
      "\tmean  = 6.300064272285185\n",
      "\tstdev = 0.4968674347868786\n",
      "p-value = 0.011891359374174631\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_pca']['syn'], eval_scores['js_pca']['cev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 6.1102822580830445\n",
      "\tstdev = 0.4233422107915738\n",
      "Benchmark:\n",
      "\tmean  = 6.0580375112178295\n",
      "\tstdev = 0.41606110392949686\n",
      "p-value = 0.7552032310461292\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_pca']['syn'], eval_scores['js_pca']['heston'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE JS-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.14232387857533355\n",
      "\tstdev = 0.032836291677329536\n",
      "Benchmark:\n",
      "\tmean  = 0.24009898403048244\n",
      "\tstdev = 0.0334652351583524\n",
      "p-value = 1.7501411460885418e-32\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_tsne']['syn'], eval_scores['js_tsne']['gbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.14232387857533355\n",
      "\tstdev = 0.032836291677329536\n",
      "Benchmark:\n",
      "\tmean  = 0.17432832832275003\n",
      "\tstdev = 0.027913822819344083\n",
      "p-value = 2.7486471299147867e-08\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_tsne']['syn'], eval_scores['js_tsne']['cev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.14232387857533355\n",
      "\tstdev = 0.032836291677329536\n",
      "Benchmark:\n",
      "\tmean  = 0.17473569447298473\n",
      "\tstdev = 0.03601983549484815\n",
      "p-value = 4.2686253658828756e-07\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['js_tsne']['syn'], eval_scores['js_tsne']['heston'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.005790042889375799\n",
      "\tstdev = 9.121297573318986e-05\n",
      "Benchmark:\n",
      "\tmean  = 0.007541947840446617\n",
      "\tstdev = 0.0005758004657698565\n",
      "p-value = 2.567448285616035e-16\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['fid']['syn'], eval_scores['fid']['gbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.005790042889375799\n",
      "\tstdev = 9.121297573318986e-05\n",
      "Benchmark:\n",
      "\tmean  = 0.004560605563891268\n",
      "\tstdev = 0.00037142154675998525\n",
      "p-value = 1.0\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['fid']['syn'], eval_scores['fid']['cev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "\tmean  = 0.005790042889375799\n",
      "\tstdev = 9.121297573318986e-05\n",
      "Benchmark:\n",
      "\tmean  = 0.003090025245840583\n",
      "\tstdev = 0.00043690669595794647\n",
      "p-value = 1.0\n"
     ]
    }
   ],
   "source": [
    "hypothesis_test(eval_scores['fid']['syn'], eval_scores['fid']['heston'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
